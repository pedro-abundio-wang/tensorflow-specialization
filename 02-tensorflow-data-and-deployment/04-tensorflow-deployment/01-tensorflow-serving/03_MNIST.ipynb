{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXdEnmVvXdUa"
   },
   "source": [
    "# Train Your Own Model and Serve It With TensorFlow Serving\n",
    "\n",
    "In this notebook, you will train a neural network to classify images of handwritten digits from the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. You will then save the trained model, and serve it using [TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2Q8bkjeYTl-"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g8r89tTPI-Kb",
    "outputId": "5166252b-6fb7-4b4f-af25-3cb238b8c152"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XGFJmWjrKttn",
    "outputId": "52b66b51-926d-4874-af5a-a3143f31899f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€¢ Using TensorFlow Version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pq-214o8SNt0"
   },
   "source": [
    "## Import the MNIST Dataset\n",
    "\n",
    "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains 70,000 grayscale images of the digits 0 through 9. The images show individual digits at a low resolution (28 by 28 pixels). \n",
    "\n",
    "Even though these are really images, we will load them as NumPy arrays and not as binary image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7MqDQO0KCaWS",
    "outputId": "703eaea1-6791-4e4b-944f-9e86947dedba"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIT-qX0QzLo-"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Scale the values of the arrays below to be between 0.0 and 1.0.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIDGu-EEzdKb"
   },
   "source": [
    "In the cell below use the `.reshape` method to resize the arrays to the following sizes:\n",
    "\n",
    "```python\n",
    "train_images.shape: (60000, 28, 28, 1)\n",
    "test_images.shape: (10000, 28, 28, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsIxeG6BzN4t"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Reshape the arrays below.\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aUw8ZxigB1Nx",
    "outputId": "7f551b7d-eff7-419b-bdf8-26b89a48e2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_images.shape: (60000, 28, 28, 1), of float64\n",
      "test_images.shape: (10000, 28, 28, 1), of float64\n"
     ]
    }
   ],
   "source": [
    "print('\\ntrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
    "print('test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcR0OKbOSj0c"
   },
   "source": [
    "## Look at a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "VQMs4v_oSo9v",
    "outputId": "a09e480d-fedd-4684-98c6-f2a2b240f287"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 42\n",
    "\n",
    "plt.imshow(test_images[idx].reshape(28,28), cmap=plt.cm.binary)\n",
    "plt.title('True Label: {}'.format(test_labels[idx]), fontdict={'size': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rn_-9OsPYnDp"
   },
   "source": [
    "## Build a Model\n",
    "\n",
    "In the cell below build a `tf.keras.Sequential` model that can be used to classify the images of the MNIST dataset. Feel free to use the simplest possible CNN. Make sure your model has the correct `input_shape` and the correct number of output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "EgMgJJynMbVY",
    "outputId": "f09b342e-ca92-4cce-cdb7-22e7a1057b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv1 (Conv2D)               (None, 13, 13, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "Softmax (Dense)              (None, 10)                13530     \n",
      "=================================================================\n",
      "Total params: 13,610\n",
      "Trainable params: 13,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Create a model.\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, strides=2, activation='relu', name='Conv1'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='Softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLzXnZT1YvS6"
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "In the cell below configure your model for training using the `adam` optimizer, `sparse_categorical_crossentropy` as the loss, and `accuracy` for your metrics. Then train the model for the given number of epochs, using the `train_images` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LTNN0ANGgA36",
    "outputId": "0885851e-51f8-47e7-96d7-6c4d53713713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3774 - accuracy: 0.8955\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2213 - accuracy: 0.9381\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1694 - accuracy: 0.9522\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1401 - accuracy: 0.9604\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1218 - accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Configure the model for training.\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# EXERCISE: Train the model.\n",
    "history = model.fit(train_images, train_labels, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Er_vrDhf4qu5"
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gMD387B93f2g",
    "outputId": "db07f75d-4468-4e0d-f4e7-edca33f3a4ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.114\n",
      "accuracy: 0.966\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Evaluate the model on the test images.\n",
    "results_eval = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "for metric, value in zip(model.metrics_names, results_eval):\n",
    "    print(metric + ': {:.3}'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGfmT8M1Yx5y"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "9uFDoDW_7HX6",
    "outputId": "f3bc22bb-00dd-4a13-dd84-b0e4c466b6f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Already saved a model, cleaning up\n",
      "\n",
      "WARNING:tensorflow:From /home/pedro/anaconda3/envs/tensorflow-specialization/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/1/assets\n",
      "\n",
      "export_path = /tmp/1\n",
      "total 80\n",
      "drwxr-xr-x 2 pedro pedro  4096 Feb  6 18:29 assets\n",
      "-rw-rw-r-- 1 pedro pedro 73427 Feb  6 18:29 saved_model.pb\n",
      "drwxr-xr-x 2 pedro pedro  4096 Feb  6 18:29 variables\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = tempfile.gettempdir()\n",
    "\n",
    "version = 1\n",
    "\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "\n",
    "if os.path.isdir(export_path):\n",
    "    print('\\nAlready saved a model, cleaning up\\n')\n",
    "    !rm -r {export_path}\n",
    "\n",
    "model.save(export_path, save_format=\"tf\")\n",
    "\n",
    "print('\\nexport_path = {}'.format(export_path))\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KziE3e9tY-hH"
   },
   "source": [
    "## Examine Your Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LU4GDF_aYtfQ",
    "outputId": "b18e83c5-5970-40a8-d941-e64f3bf76c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['__saved_model_init_op']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['__saved_model_init_op'] tensor_info:\r\n",
      "        dtype: DT_INVALID\r\n",
      "        shape: unknown_rank\r\n",
      "        name: NoOp\r\n",
      "  Method name is: \r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['Conv1_input'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 28, 28, 1)\r\n",
      "        name: serving_default_Conv1_input:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['Softmax'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 10)\r\n",
      "        name: StatefulPartitionedCall:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AsDTdBGHZAzo"
   },
   "source": [
    "## Add TensorFlow Serving Distribution URI as a Package Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "EWg9X2QHlbGS",
    "outputId": "1048b8f3-1f9c-4fc4-cae1-c654f36ae32d"
   },
   "outputs": [],
   "source": [
    "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
    "# You would instead do:\n",
    "echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "\n",
    "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4l5XkzqNZNBU"
   },
   "source": [
    "## Install TensorFlow Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ygwa9AgRloYy",
    "outputId": "797d062d-e98e-424e-fe86-631192b0b9e7"
   },
   "outputs": [],
   "source": [
    "!apt update\n",
    "!apt-get install tensorflow-model-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd_PobAKZWW8"
   },
   "source": [
    "## Run the TensorFlow Model Server\n",
    "\n",
    "You will now launch the TensorFlow model server with a bash script. In the cell below use the following parameters when running the TensorFlow model server:\n",
    "\n",
    "* `rest_api_port`: Use port `8501` for your requests.\n",
    "\n",
    "\n",
    "* `model_name`: Use `digits_model` as your model name. \n",
    "\n",
    "\n",
    "* `model_base_path`: Use the environment variable `MODEL_DIR` defined below as the base path to the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUgp3vUdU5GS"
   },
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kJDhHNJVnaLN",
    "outputId": "ded8b2b4-40b2-48ec-eba5-1dc99a4af186"
   },
   "outputs": [],
   "source": [
    "%%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "  --rest_api_port=8501 \\\n",
    "  --model_name=digits_model \\\n",
    "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IxbeiOCUUs2z",
    "outputId": "d2bc13e1-167a-49c6-d19f-41dd401a8da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2021-02-06 18:31:08.964663: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\r\n",
      "2021-02-06 18:31:08.982397: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3999980000 Hz\r\n",
      "2021-02-06 18:31:09.002110: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/1\r\n",
      "2021-02-06 18:31:09.004880: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 94418 microseconds.\r\n",
      "2021-02-06 18:31:09.005202: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\r\n",
      "2021-02-06 18:31:09.005398: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: digits_model version: 1}\r\n",
      "2021-02-06 18:31:09.006895: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...\r\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\r\n",
      "2021-02-06 18:31:09.007532: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...\r\n"
     ]
    }
   ],
   "source": [
    "!tail server.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mUrIWVRZdNu"
   },
   "source": [
    "## Create JSON Object with Test Images\n",
    "\n",
    "In the cell below construct a JSON object and use the first three images of the testing set (`test_images`) as your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dsD7KQG1m-R"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Create JSON Object\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:3].tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRdyPl4CZ5CU"
   },
   "source": [
    "## Make Inference Request\n",
    "\n",
    "In the cell below, send a predict request as a POST to the server's REST endpoint, and pass it your test data. You should ask the server to give you the latest version of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGvFyuIzW6n6"
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Fill in the code below\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/digits_model:predict', \n",
    "                              data=data, headers=headers)\n",
    "\n",
    "predictions = json.loads(json_response.text)['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FtrFMts_ackX"
   },
   "source": [
    "## Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "BxQzj34aiDz1",
    "outputId": "955b05c7-88ec-4200-cde8-2dac283ebcde"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(test_images[i].reshape(28,28), cmap = plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    color = 'green' if np.argmax(predictions[i]) == test_labels[i] else 'red'\n",
    "    plt.title('Prediction: {}\\nTrue Label: {}'.format(np.argmax(predictions[i]), test_labels[i]), color=color)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TFServing_Week1_Exercise_Answer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
